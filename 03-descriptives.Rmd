# Описатеьные статистики
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```
```{r warning=FALSE, include=FALSE, message=FALSE}
library(knitr)
library(kableExtra)
library(dplyr)
library(readr)
library(fBasics)
library(formattable)
library(plotrix)
library(stringr)
```

### О данных {-}
<span style="color: #d9d9d9">_В датасете исправлены ошибки и сделаны en_названия регионов. Те full_table_7_04.csv финальный датасет со всем-всем + доп колонки с росстата. NA заменены на нули. Мое + Алексей. Надо объединить кодбук. Все преобразования датасета в файле scr1.R_</span>

```{r warning=FALSE,  include=FALSE, message=FALSE}
df <- read_csv("~/Desktop/Applied_Geography/rnf_model/grantbook/data/full_table_7_04.csv")
#write.csv(alexey_database, "alexey_database.csv",row.names = TRUE, fileEncoding = "UTF-8" )
```

### Описательные статистики {-}
```{r warning=FALSE}
df_cut_stat <- df %>% 
  select(35:40)
df_cut_stat[df_cut_stat==0] <- NA
J <- basicStats(df_cut_stat)
J <- data.frame(t(J))
J <- formattable(J, digits = 2) %>% select(1:9)

knitr::kable(J, booktabs = T) %>%
  kable_styling(font_size = 12)
#write.csv(J, "descr_stat.csv",row.names = TRUE, fileEncoding = "UTF-8" )
```

Смотрим на NA: от 21 до 38 регионов не получают грантов РНФ вообще (за 2014-2019 гг). Медиана в разы меньше среднего + третий квантиль колеблется от 6 до 16 при максимуме от 134 до 827. Рапределие далеко от нормального и будет иметь очень длинный хвост. Очень неоднородное кол-во грантов по годам: в 2015 выдали 418 грантов, в 2019 -- 2096.

### Таблицы {-}

Уйдем от штук на доли, чтобы нивелировать сильный разброс в кол-ве выданных грантов по годам. 

Попробуем поймать таблицей какую-нибудь красивую тенденцию, например, поишем регионы, которые год от года увеличивают совою долю грантов.  

###### Дурацкая таблица: _доля грантов РНФ (от всех выданных грантов РНФ по стране в соответствующй год)_ {-}
```{r warning=FALSE, message=FALSE}
# возвращаемся к df_cut_share
df_color <- df %>% 
  mutate(change2015 = sh_2015-sh_2014,
         change2016 = sh_2016-sh_2015,
         change2017 = sh_2017-sh_2016,
         change2018 = sh_2018-sh_2017,
         change2019 = sh_2019-sh_2018) %>% 
  mutate_if(is.numeric, round, digits = 5)

#write.csv(df_color, "df_color.csv",row.names = TRUE, fileEncoding = "UTF-8" )
```

```{r warning=FALSE, message=FALSE}

g <- formattable(df_color, list(
  `sh_2015`= formatter("span", style = ~ style(color = ifelse(`sh_2015` >`sh_2014`, "green", "red")),
                    ~ icontext(ifelse(`sh_2015` >`sh_2014`,"arrow-up", "arrow-down"), `sh_2015`)),
  `sh_2016`= formatter("span", style = ~ style(color = ifelse(`sh_2016` >`sh_2015`, "green", "red")),
                       ~ icontext(ifelse(`sh_2016` >`sh_2015`,"arrow-up", "arrow-down"), `sh_2016`)),
  `sh_2017`= formatter("span", style = ~ style(color = ifelse(`sh_2017` >`sh_2016`, "green", "red")),
                       ~ icontext(ifelse(`sh_2017` >`sh_2016`,"arrow-up", "arrow-down"), `sh_2017`)),
  `sh_2018`= formatter("span", style = ~ style(color = ifelse(`sh_2018` >`sh_2017`, "green", "red")),
                       ~ icontext(ifelse(`sh_2018` >`sh_2017`,"arrow-up", "arrow-down"), `sh_2018`)),
  `sh_2019`= formatter("span", style = ~ style(color = ifelse(`sh_2019` >`sh_2018`, "green", "red")),
                       ~ icontext(ifelse(`sh_2019` >`sh_2018`,"arrow-up", "arrow-down"), `sh_2019`)))) %>%
  select(3, starts_with("sh_2")) 

as.datatable(g) # стрелочки пропали из за нее 
```


Столбец _sh_2014_ не окрашен, так как цвет говорит об изменении к предыдущему году. Никакой супер интересной тенденции в табличке не видно, на первый взгляд все регионы теряют доли и прирастают ими довольно хаотично. Ну кроме некоторых регионов, у которых стабильный 0. Их легко увидеть, если все столбики отсортировать по возрастанию имеющимися стрелочками.

***

$HHI=доля^2+S_{2}^{2}+...+S_{n}^{2}}$
###### Таблица получше: _доля грантов РНФ в 2014-2016 (first_period) и в 2017-2019 (second_period) (от всех выданных грантов РНФ по стране в соответствующй период)_ {-}
```{r warning=FALSE, message=FALSE}
#colnames(df_color)

f <- formattable(df_color, list(
  `second_period`= formatter("span", style = ~ style(color = ifelse(`second_period` >`first_period`, "green", "red")),
                    ~ icontext(ifelse(`second_period` >`first_period`,"arrow-up", "arrow-down"), `second_period`)))) %>%
  select(3, 68, 69) 
as.datatable(f)

```

Видим стабильные ~40 % у Москвы, 11-14 % у Петербурга и 9 % у Новосибирска. Не выходя из Топ-10 уже видим у Приморья и Ростовской области по 1%, на остальные 9 страничек даже и не перелисытвать не надо.

У _first_period_ и _second_period_ коэфицент корреляции что-то около 0,85-0,9, то есть, если регион получал гранты в 2014-2016 году, то он будет получать примерно на таком же уровне в 2017-2019. И наоборот, те у кого грантов не было с самого начала, то во втором периоде чуда не случится. (РАЗБЕРИСЬ С КОЭФИЦЕНТАМИ КОРРЕЛЯЦИИ, КАКОЙ ИЗ НИХ НУЖЕН ПРИ ТАКОМ РАСПРЕДЕЛЕНИИ)

### Боксплоты {-}

Хочется посмотреть выбросы, причем поймать как будут сжиматься медиана и максимальное значаение выданных грантов, когда мы будем эти выбросы постепенно убирать.

```{r warning=FALSE}
# long 85 * 6 = 510
library(tidyr)

data_long <- df %>% select(3, region_id,starts_with("rnf20"))
data_long <- gather(data_long, condition, measurement, rnf2014:rnf2019, factor_key=TRUE)
data_long <- data_long %>% mutate(condition = gsub("[^0-9.-]+", "", condition))
data_long <- data_long %>%
  mutate(measurement = if_else(is.na(measurement), 0, measurement))

data_long <- as.data.frame(data_long)

data_long_cut_11_12_38 <- data_long %>% 
  dplyr::filter(region_id != 11) %>% 
  dplyr::filter(region_id != 12) %>% 
  dplyr::filter(region_id != 38) 

data_long_cut_11_12_38_plus <- data_long_cut_11_12_38 %>% 
  dplyr::filter(region_id != 33) %>% 
  dplyr::filter(region_id != 36) %>% 
  dplyr::filter(region_id != 60) %>% 
  dplyr::filter(region_id != 68) %>% 
  dplyr::filter(region_id != 73) 

par(mfrow=c(1,1), oma=c(0,0,2,0))
boxplot(data_long$measurement ~ data_long$region_id,
        xlab = "I. Все регионы",
        ylab = "Гранты в шт") # 11, 12, 38
mtext("Распределение грантов РНФ по регионам России за 2014-2019", line=0, side=3, outer=TRUE, cex=-10)
```
```{r}
boxplot(data_long_cut_11_12_38$measurement ~ data_long_cut_11_12_38$region_id,
        xlab = "II. Без Топ-3",
        ylab = "Гранты в шт")  # 33 36 60 68 73
```
```{r}
boxplot(data_long_cut_11_12_38_plus$measurement ~ data_long_cut_11_12_38_plus$region_id,
        xlab = "III. Без ТОП-8",
        ylab = "Гранты в шт")
```

Тут у нас уже боксплоты по панели 2014-2019. _Ось x_ -- номер региона, на первом графике сильно выбивабтся Москва(11), Санкт-Петербург(12) и Новосибирская обл(38). Например, Москва за 2014-2019 год имела максимальное кол-во грантов ~ 600 шт (по боксплоту плохо видно точное число), при этом медиана у Москвы была за эти годы примерно на уровне ~ 400 грантов. Если мы отрежем Топ-3 регона, то получим рисунок "Без Топ-3" у которого шкала _оси y_ гораздо короче, и тут у нас появлось пять новых "регинов-выбросов". Убираем их и получаем, график "Без Топ-8", где 77 регионв вполне себе уживаются в шкале до ~30 грантов. 


# Переменные из РИНЦа

Всего в РИНЦе (база Даши) есть 995 организации. Они расположены в ~~80~~ 82 регионах России из 85 (нет организаций в Ненецком АОк, Чукотском АОк  и Ямало-Ненецком АОк).

Кол-во организаций по регионам в таблице ⬇️ 
```{r warning=FALSE, message=FALSE}
nf <- read_delim("data/final_table_rints.csv", 
    ";", escape_double = FALSE, trim_ws = TRUE)
rf <- nf %>% group_by(region_rus_from_map) %>% count()
rf <- formattable(rf)
as.datatable(rf)
```

***

У Даши в датасете есть **626 переменных**, я не могу разобраться 

 - какие из них лучше брать
 
 - на что лучше нормировать, чтобы регионы стали сопоставимы (люди, кол-во организаций)
 
 - среднее брать или медиану

[Датасет](https://docs.google.com/file/d/1AfGyHBd9Ech3LQTaYUL71KwSU8pBS_A-/edit?filetype=msexcel) и [кодбук](https://docs.google.com/file/d/1MlRau9SWRc3hLhG5bX_CXm3VOb0LRqwd/edit?filetype=msexcel)

## Люди из ядра РИНЦа {-}

Я выбрала один из показателей -- <span style="background-color: #ffff99">Число авторов, имеющих публикации, входящие в ядро РИНЦ, за 5 лет</span> и вот что получилось (+добавила кол-во ун-тов в регионе). 
```{r warning=FALSE, message=FALSE}
p <- data.table::setDT(nf)[ , list(mean = mean(N_aut_crinc5), 
                                   median = median(N_aut_crinc5),
                                   min = min(N_aut_crinc5),
                                   max = max(N_aut_crinc5),
                                   count_of_Uni = .N), by = .(region_rus_from_map)]
p <- formattable(p)
as.datatable(p)
```

## Доля классных публикаций{-}

Посчитаем <span style="background-color: #ffff99">долю (%) публикаций Scopus и Web of Science от общего числа публикаций **в организации**</span>  по такой формуле:

$$ \frac{sco\_wos\_5}{elab\_5 +1} * 100$$
где,

$sco\_wos\_5$ -	число статей в журналах, входящих в Web of Science или Scopus, за 5 лет (переменная в кодбуке -- _N_pub_WOSSC5_)

$elab\_5$ - число публикаций на elibrary, за 5 лет (переменная в кодбуке -- _N_elibrary5_)

Единицу в знаменатель мы добавили, чтобы не отрезать организации, у которых 0 публикаций на elibrary.ru за 5 лет (да, такие тоже есть, 16 из 995). Потом их можно и отрезать, пока сохраним.

<span style="background-color: #ffff99">**После этого агрегируем до уровня региона**</span>  и пока непонятно, что лучше медиана или среднее, сделаем оба варианта. Т.е. порядок действий важен! У нас такой: по каждой из 995 организаций счиатем долю классных публикаций. Потом группируем по региону и смотрим что в среднем. Сохраню столбец с кол-вом организаций в регионе, чтобы вы не пугались, что мы получили на первых местах Ленинградскую и Томскую области. Я проверила, никакой ошибки. Наши данные говорят именно об этом. Видимо надо вычищать мусор из Москвы (убирать те организации, у которых нули, либо кого-то добавлять в датасет, кого тут нет, но я не очень понимаю кого у нас нет)

```{r warning=FALSE, message=FALSE}
# код для убирания процентов в скобках
nk <- nf %>%
  mutate(N_pub_WOSSC5_persent = gsub("[\\(\\)]", "", regmatches(N_pub_WOSSC5, gregexpr("\\(.*?\\)", N_pub_WOSSC5)))) %>% 
  mutate(N_pub_WOSSC5_persent = gsub("%", "", N_pub_WOSSC5_persent)) %>% 
  mutate(N_pub_WOSSC5_persent = gsub(",", ".", N_pub_WOSSC5_persent)) %>% 
  mutate(N_pub_WOSSC5 = gsub("\\(.*","",N_pub_WOSSC5)) %>% 
  mutate(N_pub_WOSSC5 = as.numeric(N_pub_WOSSC5),
         N_pub_WOSSC5_persent = as.numeric(as.character(N_pub_WOSSC5_persent)))
```


```{r warning=FALSE, message=FALSE}
options(digits = 3)
h <- data.table::setDT(nk)[ , list(mean = mean(100*(N_pub_WOSSC5/(N_elibrary5+1))), 
                                   median = median(100*(N_pub_WOSSC5/(N_elibrary5+1))),
                                   min = min(100*(N_pub_WOSSC5/(N_elibrary5+1))),
                                   max = max(100*(N_pub_WOSSC5/(N_elibrary5+1))),
                                   count_of_Uni = .N), by = .(region_rus_from_map)]
h <- formattable(h)
as.datatable(h)
```

***

## Доля классных публикаций V 2.0 {-}

<span style="background-color: #ffff99"> Уберем всех у кого за последние пять лет было < 25 публикаций в Скопус и WoS </span> . Всю остальную процедуру сохраним. У нас сразу их 995 организация осталось 525. Ленинградская область всё так же нерушима. Москва подтянулась.

```{r warning=FALSE, message=FALSE}
# код для убирания процентов в скобках
nl <- nf %>% 
  mutate(N_pub_WOSSC5_persent = gsub("[\\(\\)]", "", regmatches(N_pub_WOSSC5, gregexpr("\\(.*?\\)", N_pub_WOSSC5)))) %>% 
  mutate(N_pub_WOSSC5_persent = gsub("%", "", N_pub_WOSSC5_persent)) %>% 
  mutate(N_pub_WOSSC5_persent = gsub(",", ".", N_pub_WOSSC5_persent)) %>% 
  mutate(N_pub_WOSSC5 = gsub("\\(.*","",N_pub_WOSSC5)) %>% 
  mutate(N_pub_WOSSC5 = as.numeric(N_pub_WOSSC5),
         N_pub_WOSSC5_persent = as.numeric(as.character(N_pub_WOSSC5_persent)))

nl <- nl %>% dplyr::filter(N_pub_WOSSC5 > 24) 

```


```{r warning=FALSE, message=FALSE}
options(digits = 3)
h <- data.table::setDT(nl)[ , list(mean = mean(100*(N_pub_WOSSC5/(N_elibrary5+1))), 
                                   median = median(100*(N_pub_WOSSC5/(N_elibrary5+1))),
                                   min = min(100*(N_pub_WOSSC5/(N_elibrary5+1))),
                                   max = max(100*(N_pub_WOSSC5/(N_elibrary5+1))),
                                   count_of_Uni = .N), by = .(region_rus_from_map)]
h <- formattable(h)
as.datatable(h)
```



## Импакт-фактор журналов {-}

У нас естьпеременная **средневзвешенный импакт-фактор журналов, в которых были опубликованы статьи** (по годам с 2010 по 2019) (переменные у Даши _y2010mean_imp_j_ и тд)


```{r warning=FALSE, message=FALSE, eval=FALSE}
# Спрячем пока
**2) число авторов WoS/Scopus в организациях**

- N_aut_WOSSC5	Число авторов, имеющих статьи в журналах, входящих в Web of Science или Scopus,за 5 лет
- y2010n_aut_wossc	Число авторов статей в журналах Web of Science или Scopus,2010 год
.
.
- y2019n_aut_wossc	Число авторов статей в журналах Web of Science или Scopus,2019 год


# ЭТОТ КУСОК ДЕРЬМА НЕ РЕНДЕРИТСЯ, ПОЭТОМУ 
nf_2 <- nf
m <- c(as.character(expression(imp_j_pub5, 
                    y2010mean_imp_j, 
                    y2011mean_imp_j, 
                    y2012mean_imp_j, 
                    y2013mean_imp_j,
                    y2014mean_imp_j,
                    y2015mean_imp_j,
                    y2016mean_imp_j,
                    y2017mean_imp_j,
                    y2018mean_imp_j,
                    y2019mean_imp_j,
                    N_aut_WOSSC5,
                    y2010n_aut_wossc,
                    y2011n_aut_wossc,
                    y2012n_aut_wossc,
                    y2013n_aut_wossc,
                    y2014n_aut_wossc,
                    y2015n_aut_wossc,
                    y2016n_aut_wossc,
                    y2017n_aut_wossc,
                    y2018n_aut_wossc,
                    y2019n_aut_wossc)))
nf_2[,m] <- apply(nf_2[,m], 2, function(y) as.numeric(gsub(",", ".", y)))

# ЗАПИШЕМ РУКАМИ И ОТКРОЕМ ЗАНОВО

write.csv(nf_2, "nf_2.csv", ,row.names = TRUE, fileEncoding = "UTF-8" )
#nd[, c(1:2,4)] <- apply(nd[, c(1:2,4)], 2, function(y) as.numeric(gsub(",", ".", y)))
#nf %>% select(m) %>% summary()
```
 
 
ЧТО ДЕЛАТЬ С НУЛЯМИ? ЭТО ОЧЕНЬ ВАЖНО! В данных есть три знака: -, NA, 0. Если мы считаем среднее, то: 

1) $(2 + 3 + 0)/3  = 2$ 

2) $(2 + 3 + NA)/2  = 3$ - выбран этот вариант, появились NaN = mean(NA,NA,NA)


```{r warning=FALSE, message=FALSE}

nf_2 <- read_csv("~/Desktop/Applied_Geography/rnf_model/grantbook/data/nf_2.csv")
nf_2[nf_2 == "-"] <- NA
#nf_2[is.na(nf_2)] <- 0

nf_2 <- nf_2 %>%
   dplyr::mutate(imp_2011_13 = 
             rowMeans(data.frame(y2011mean_imp_j, y2012mean_imp_j, y2013mean_imp_j), na.rm = TRUE),
           imp_2014_16 = 
             rowMeans(data.frame(y2014mean_imp_j, y2015mean_imp_j, y2016mean_imp_j), na.rm = TRUE),
           imp_2017_19 = 
             rowMeans(data.frame(y2017mean_imp_j, y2018mean_imp_j, y2019mean_imp_j), na.rm = TRUE),
           aut_wos_sc_2011_13 = 
             rowMeans(data.frame(y2011n_aut_wossc, y2012n_aut_wossc, y2013n_aut_wossc), na.rm = TRUE),
           aut_wos_sc_2014_16 = 
             rowMeans(data.frame(y2014n_aut_wossc, y2015n_aut_wossc, y2016n_aut_wossc), na.rm = TRUE),
           aut_wos_sc_2017_19 = 
             rowMeans(data.frame(y2017n_aut_wossc, y2018n_aut_wossc, y2019n_aut_wossc), na.rm = TRUE))
      
```
 
 
Заменяем NaN на 0. ПОДУМАТЬ О ТОМ КАКОЕ ЕСТЬ СМЕЩЕНИЕ И КУДА

Посмотрим на три периода: 2011-2013, 2014-2016, 2017-2019.

Таблица с <span style="background-color: #ffff99"> медианными значениями _средневзвешенного импакт-фактора журналов, в которых были опубликованы статьи_ </span> по этим трем периодам. Mean, min и max просто не влезли, пришлось скрыть. 

В таблице еще больший ужас. Камчатка выпрыгнула в топы. 

```{r warning=FALSE, message=FALSE}

# Заменяем NaN на 0 ПОДУМАЙ КАК ЭТОТ СКРИПТ СЧИТАЛ ДАЛЕЕ, СТАВИТ ЛИ ОН na.rm автоматом?
nf_2[nf_2 == "NaN"] <- 0
options(digits = 2)
t <- data.table::setDT(nf_2)[ , list(#mean11_13 = mean(imp_2011_13), 
                                     #mean14_16 = mean(imp_2014_16),
                                     #mean17_19 = mean(imp_2017_19),
                                   median11_13 = median(imp_2011_13),
                                   median14_16 = median(imp_2014_16),
                                   median17_19 = median(imp_2017_19),
                                   #min11_13 = min(imp_2011_13),
                                   #min14_16 = min(imp_2014_16),
                                   #min17_19 = min(imp_2017_19),
                                   #max11_13 = max(imp_2011_13),
                                   #max14_16 = max(imp_2014_16),
                                   #max17_19 = max(imp_2017_19),
                                   count_uni = .N), by = .(region_rus_from_map)]
t <- formattable(t)
as.datatable(t)

#nn <- nf_2 %>% select(4,m) %>% filter()
#font.size <- "10pt"

#t %>% 
#   DT::datatable(
#     options=list(
#       initComplete = htmlwidgets::JS(
#          "function(settings, json) {",
#          paste0("$(this.api().table().container()).css({'font-size': '", font.size, "'});"),
#          "}")
#       ) 
#     ) %>% 
#  DT::formatRound(columns = c(2:4), digits = 3)
```
 
Я проверила, ошибки нет. Такая же табличка <span style="background-color: #ffff99"> с импакт-фактрором, только со средними значениями </span> и я ради наглядности добавила еще столбик с максимумом за период 2017-2019, чтобы было понять, что просто выигрывают регионы, у которых нет стремных универов, которые своими нулями утягивают и медиану и среднее вниз.
 
```{r warning=FALSE, message=FALSE}

# Заменяем NaN на 0 ПОДУМАЙ КАК ЭТОТ СКРИПТ СЧИТАЛ ДАЛЕЕ, СТАВИТ ЛИ ОН na.rm автоматом?
nf_2[nf_2 == "NaN"] <- 0
options(digits = 2)
p <- data.table::setDT(nf_2)[ , list(mean11_13 = mean(imp_2011_13), 
                                     mean14_16 = mean(imp_2014_16),
                                     mean17_19 = mean(imp_2017_19),
                                   #median11_13 = median(imp_2011_13),
                                   #median14_16 = median(imp_2014_16),
                                   #median17_19 = median(imp_2017_19),
                                   #min11_13 = min(imp_2011_13),
                                   #min14_16 = min(imp_2014_16),
                                   #min17_19 = min(imp_2017_19),
                                   #max11_13 = max(imp_2011_13),
                                   #max14_16 = max(imp_2014_16),
                                   max17_19 = max(imp_2017_19),
                                   count_uni = .N), by = .(region_rus_from_map)]
p <- formattable(p)
as.datatable(p)
```


## HHI {-}

$$HHI=S_1^2 + S_2^2 + ... + S_n^2$$,

где $S_1, S_2 ... S_n$  — выраженные (в процентах) доли регионов.

В случае чистой монополии, когда все гранты будут у одного региона, $HHI=10000$. 
Для двух регионов с равными долями $HHI=50^2 + 50^2 = 5000$, для 100 регионов (у нас столько нет)) с долей в 1 % $HHI=100$. Таким образом индекс Херфиндаля реагирует на  долю каждого региона от общего кол-ва грантов, выданных в стране к конкретном году.


```{r warning=FALSE, include=FALSE }
result_2 <- read_delim("data/result_2.csv", 
    ";", escape_double = FALSE, trim_ws = TRUE)
```


```{r warning=FALSE, message=FALSE}
library(dplyr)
library(ggplot2)
```

```{r warning=FALSE, message=FALSE}
result_HHI <- result_2 %>% mutate(sq_sh_2014 =(100*sh_2014)^2,
                                  sq_sh_2015 =(100*sh_2015)^2,
                                  sq_sh_2016 =(100*sh_2016)^2,
                                  sq_sh_2017 =(100*sh_2017)^2,
                                  sq_sh_2018 =(100*sh_2018)^2,
                                  sq_sh_2019 =(100*sh_2019)^2) 

colnames(result_2)
dd <- data.frame(year = c(2014:2019),
                 HHI = c(sum(result_HHI$sq_sh_2014),
                         sum(result_HHI$sq_sh_2015),
                         sum(result_HHI$sq_sh_2016),
                         sum(result_HHI$sq_sh_2017),
                         sum(result_HHI$sq_sh_2018),
                         sum(result_HHI$sq_sh_2019)))

ggplot(dd) +
  geom_col(aes(dd$year,dd$HHI))+
  scale_x_continuous(breaks = c(2014:2019))
```

Не забудь про ttest. Катерина правильно сказала, что это незначимая разница по годам.


 
